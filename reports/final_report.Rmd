---
title: "Assessing Stem Cell Therapeutics in Murine Models"
author: | 
  | Giles Carlos, 54951701, gpcarlos@uci.edu
  | Nathan Gin, 67117388, nbgin@uci.edu
  | Alexander Nathaneal, 46645315, anathana@uci.edu
  | Vinh Nguyen, 50036019, vinhhn2@uci.edu
  | Owen Sitiabudi, 19975215, ositiabu@uci.edu
date: "Github Repository: https://github.com/gilescarlos/Stats-170-Cap-Stone"
output:
  pdf_document: 
    number_sections: true
  html_document:
    number_sections: true
---

```{r echo = FALSE, include = FALSE}
library(tidyverse)
library(kableExtra)
library(knitr)
library(dplyr)
library(readr)
library(ggplot2)
library(ggpubr)
library(jpeg)
library(png)
library(gridExtra)

post_injury <- read_csv(here::here("data/post_injury.csv"))

dlc_train <- read_csv(here::here("data/dlc_train_example_video.csv"))

frame <- readPNG(here::here("data/train/UCI_HD_Label-NG-2023-05-19/labeled-data/20230112_145948/img0924.png"))
```


# Introduction and Problem Statement

Spinal cord injury (SCI) is a debilitating condition that impacts up to 300,000 individuals in the U.S. each year. As such, a significant focus of stem cell research is dedicated to developing therapeutics that could help bring affected individuals’ livelihood back. Likewise, the tests and methods used to assess different therapeutics are incredibly important. The efficiency and rigor of these tests allow for discovery of novel therapies and help advance the research field dedicated to solving spinal cord injury. The ladder beam test is a behavioral method for assessing recovery following SCI in murine models. There are 3 types of mice: Knock-out, Wildtype, and Vehicle. The Knock-out mice have their CD44 gene removed to study its absent effect in recovery. The Wildtype are the control group while the Vehicle type have an additional injection. During the test, mice must walk across a ladder with fifty rungs. Injured mice are expected to have more missteps while recovering mice should have more plantar or sufficient steps. However, to properly utilize this test our sponsors must spend several hours analyzing hundreds of videos of mice completing the task in order to individually score each mouse's performance. Consequently, this tedious process tends to slow down the lab's workflow and some automation would provide a significant increase in efficiency. Streamlining the ladder beam task and its data analysis would allow for significant efficiency in retrieving data necessary for the advancement of SCI research and therapeutics. Our primary goal is to use appropriate machine learning algorithms and build off existing research to aid in the lab’s data collection process for the ladder beam task. Secondly, we will assess the effectiveness of different treatments through appropriate statistical models and hypothesis tests. 

# Related Work

Several other labs have encountered this bottleneck in efficiency and have aimed to address this problem as well. One such solution is DeepLabCut^[Mathis, A., Mamidanna, P., Cury, K.M. et al. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci 21, 1281–1289 (2018). https://doi.org/10.1038/s41593-018-0209-y], which is an open source software developed in Python that utilizes a deep neural network to track various body parts in multiple species across a broad collection of behaviors or physical assessments. Another study was able to utilize the software to conduct a comprehensive 3D gait analysis of mice after focal cerebral ischemia^[Weber, R.Z., Mulders, G., Kaiser, J. et al. Deep learning-based behavioral profiling of rodent stroke recovery. BMC Biol 20, 232 (2022). https://doi.org/10.1186/s12915-022-01434-9]. The authors concluded that using a previously trained data set for tracking mice movement, their own recordings of mice completing the ladder beam task, and the DeepLabCut neural network provides accurate and sensitive data to describe the complex recovery of rodents following a stroke. Other researchers have also been successful in building upon DeepLabCut and creating their own toolbox utilizing a convolutional neural network appropriate for their recording equipment^[Aljovic, A., Zhao, S., Chahin, M. et al. A deep learning-based toolbox for Automated Limb Motion Analysis (ALMA) in murine models of neurological disorders. Commun Biol 5, 131 (2022). https://doi.org/10.1038/s42003-022-03077-6].

# Data Sets

We obtained our data from our sponsors at the UCI Stem Cell Research Center. Specifically, we received about a hundred videos of mice completing the ladder beam task and the corresponding manually labeled excel sheet corresponding to the videos. 

```{r echo = FALSE}
options(digits = 3)

kable(head(post_injury, 10),
      escape = T, 
      col.names = c("Animal ID", "Total Good Steps", "Total Bad Steps", "Avg Good Steps", "Avg Bad Steps", "LB Score", "Type"),
      caption = "Example of First 10 Rows of Manually Input Data Set Obtained from Ladder Beam Task",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

```{r, results= FALSE, echo = FALSE}
n_row <- nrow(post_injury)
n_col <- ncol(post_injury)
summary(post_injury)
str(post_injury)
```

<<<<<<< HEAD
The post_injury data set has `r n_row` rows and `r n_col` columns where each column represents a single variable. The animal and type variables are categorical (nominal) and the rest of the variables are numerical (discrete). There are three types of mice - Wildtype, Knock-out and Vehicle. On average, each mouse has 42.83 good steps and 7.15 bad steps. The mean lb score of the mice is 85.69, with a lowest of 72.33 and a highest of 97.00. The highest total good steps the mouse has is 291 and the lowest is 217 good steps. While for the bad steps, the highest is 83 and the lowest is 9 bad steps.
=======
The post_injury data set has `r n_row` rows and `r n_col` columns where each column represents a single variable. The animal and type variables are categorical (nominal) and the rest of the variables are numerical (discrete). Total_good and Total_bad measures the quality of the steps of the mouse as it traverse through the ladder beam. Type variable indicate 1 of the 3 mouse types: wild (w), knock-out (k), and vehicle (v). Lb_score shows the overall performance of each mouse On average, each mouse has 42.83 good steps and 7.15 bad steps. The mean lb score of the mice is 85.69, with a lowest of 72.33 and a highest of 97.00. The highest total good steps the mouse has is 291 and the lowest is 217 good steps. While for the bad steps, the highest is 83 and the lowest is 9 bad steps.
>>>>>>> 2147f11e9d38e314c422005cd6c8ceef4ae8aef8

```{r echo = FALSE}

kable(head(dlc_train, 10),
      col.names = c("Video", "Frame", "Bodypart", "X", "Y"),
      escape = T, caption = "Example of First 10 Rows of Training Data from a Single Video",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

The above table corresponds to a single training data set from one video of the ladder beam task being completed. From this particular video, nineteen frames were extracted which produced a data set with `r nrow(dlc_train)` rows and `r ncol(dlc_train)` columns. Each row represents a the location of one of the mouse's paws during a particular frame from a specific video. The video column indicates what video the frames were extracted from. Likewise, the frame column indicates which particular frame the body part was being tracked. Lastly, the body part, x, and y column correspond to which paw, the x coordinate, and the y coordinate, respectively. As we obtain more videos from our collaborators we plan on having a much larger training set with multiple videos and more frames. 

# Overall Technical Approach

## Data Wrangling

In order to utilize the videos provided by us, we needed an efficient tool for extracting frames in the video and labeling the location of mouse paws. We utilized DeepLabCut (DLC), an open source Python tool for developing models capable of tracking animal behavior and movement. The process for extracting our data from this tool goes as follows. First, we input a video or list of videos that we wish to obtain training data from into DLC. DLC then extracts a particular set of frames from each video according to the options we specify. Next, we individually label each frame by marking the location of each of the four mouse paws. Lastly, from those labeled frames DLC produces a training data set. 

However, the training data must then be pre-processed since the outputted format is not efficient to work with. As shown in the table below, each frame corresponds to a single row but the names for the columns need to be cleaned. In order to clean the training dataset initially produced by DLC into the table described in the Dataset section, the column names had to be changed and rows could be broken down to represent multiple body parts. First, we removed the scorer's name since it is irrelevant to the data. The columns containing the video file and the frame were given appropriate names. Then, each body part was given a correct column name. For example, bodypart1 corresponded to the front left paw of the mouse. Lastly, each individual row was transformed into four rows, one corresponding to each paw of the mouse at that specific frame. 

```{r message = FALSE, echo = FALSE}
unclean_train_data <- read_csv(here::here("data/train/UCI_HD_Label-NG-2023-05-19/labeled-data/20230112_145948/CollectedData_NG.csv"))

kable(head(unclean_train_data[,1:5], 10),
    escape = T, caption = "Example of First 10 Rows and 5 Columns of Uncleaned Training Data from a Single Video",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```



## Exploratory Data Analysis

```{r echo = FALSE}
post_injury %>% 
  mutate(type = case_when(type == "w" ~ "Wildtype", 
                          type == "k" ~ "Knock-out",
                          type == "v" ~ "Vehicle")) %>% 
  ggplot(aes(x = type, y = ave_bad)) + 
  geom_boxplot() + 
  labs(x = "Type of Mice", y = "Average # Errors", title = "Distribution of Ladder Beam Performance Across Mice Groups") + 
  theme_classic()
```

When comparing the three groups of mice, we can see that on average the knock-out mice performed the worst while the wild type performed the best. The vehicle group and wildtype group appear to have similar variance while the knock-out group's variance is slightly higher. Based on the plot, there may be some evidence that the stem cell therapeutic helps certain groups of mice in their recovery a little more. 

```{r echo = FALSE, warning = FALSE}
track_paws1<- dlc_train %>% 
  filter(frame == "img0924.png") %>% 
  filter(bodypart %in% c("back_left_paw", "back_right_paw", "front_left_paw", "front_right_paw")) %>% 
  mutate(bodypart = case_when(bodypart == "back_left_paw" ~ "Back Left Paw",
                   bodypart == "back_right_paw" ~ "Back Right Paw",
                   bodypart == "front_left_paw" ~ "Front Left Paw",
                   bodypart == "front_right_paw" ~ "Front Right Paw")) %>% 
  ggplot(aes(x = x, y = y, color = bodypart)) + 
  background_image(frame) +
  geom_point() +
  ylim(3840, 0) + 
  xlim(0, 2160) +  
  labs(x = "X",
       y = "Y", 
       color = "Body Part") + 
  theme(legend.position = "none")

track_paws2 <- dlc_train %>% 
  filter(bodypart %in% c("back_left_paw", "back_right_paw", "front_left_paw", "front_right_paw")) %>% 
  mutate(bodypart = case_when(bodypart == "back_left_paw" ~ "Back Left Paw",
                   bodypart == "back_right_paw" ~ "Back Right Paw",
                   bodypart == "front_left_paw" ~ "Front Left Paw",
                   bodypart == "front_right_paw" ~ "Front Right Paw")) %>% 

  ggplot(aes(x = x, y = y, color = bodypart)) + 
  geom_point() +
  ylim(3840, 0) + 
  xlim(0, 2160) + 
  labs(x = "X",
       y = "Y", 
       color = "Body Part") + 
  theme(legend.position = c(0.25, 0.875),
        legend.key.size = unit(0.25, 'cm'))

grid.arrange(track_paws1, track_paws2, ncol = 2)
```

The two plots above, describe how the paws are tracked in a video and the general behavior of each paw. The first plot, indicates that we are tracking each paw by emphasizing the location of the toes. The second plot describes the natural behavior one would expect for the paws of a mouse. That is, the front paws remain in front of the back paws for majority of the video. It must be noted that the recordings were not done with a stationary camera so although the mouse may have been moving forward, during the frames it may appear that the mouse is not moving that much. 

```{r echo=FALSE, message = FALSE}
post_injury %>%
  mutate(type = case_when(
    type == "w" ~ "Wildtype",
    type == "k" ~ "Knock-out",
    type == "v" ~ "Vehicle"
  )) %>%
  ggplot(aes(x = total_good)) +
  geom_density(fill = "white", alpha = 0.5) +
  labs(
    title = "Distribution of Total Good Steps Across Mice Groups",
    x = "Total Good Steps",
    y = "Density"
  ) +
  facet_wrap(vars(type))
```

```{r echo=FALSE, message = FALSE}
post_injury %>%
  mutate(type = case_when(
    type == "w" ~ "Wildtype",
    type == "k" ~ "Knock-out",
    type == "v" ~ "Vehicle"
  )) %>%
  ggplot(aes(x = total_bad)) +
  geom_density(fill = "white", alpha = 0.5) +
  labs(
    title = "Distribution of Total Bad Steps Across Mice Groups",
    x = "Total Bad Steps",
    y = "Density"
  ) +
  facet_wrap(vars(type))
```

<<<<<<< HEAD
The above two graphs show the distribution of the total good and bad steps across the mice groups. According to the graphs, almost every mouse having different numbers of total good and bad steps. The Vehicle type has less good steps compared to the Wildtype, and more bad steps compared to the Wildtype. Overall, the total good steps and bad steps across mice groups are evenly distributed. 

## Data Modeling

Our main interest is to build a model that can accurately track a mouse paw as they complete the ladder beam task and capable of classifying mouse steps as good ones or bad ones. As a result, we utilize DeepLabCut for the object detection model, which is a software package for animal pose estimation that allows the training of a deep neural network using trained data. 

We start by uploading the videos and then extracting the frames to be manually labeled as the training data. We design the skeleton of the mouse and manually label the mouse's body parts and rungs throughout these frames for the neural network to be trained on. Through this process we then can create the training data sets. After obtaining the training data sets, we train the network, while saving for every 100 iterations with a total of 166500 iterations. We then evaluate the trained network by computing the mean average Euclidean error between the manual labels and the ones predicted by the network. Then we can use the trained network to analyze new videos and plot the mouse steps in x and y coordinate. 

We also built an ANOVA model comparing the total bad steps between the three types of mice. The Knock-out type has an average bad steps of 7.6, the Vehicle type has an average bad steps of 7.8, and the Wild type has an average bad steps of 6.1. Since the p-value is 0.543, then we can conclude that the average number of errors is not significantly different among the three types of mice after treatment. Based on the QQ-plot, we can see that there is a heavy tail, which means that there is a possible violation to the normality assumption because of the small sample size. 



=======
The above two graphs show the distribution of the total good and bad steps across the mice groups. According to the graphs, almost every mouse having different density of total good and bad steps. The Vehicle type has less good steps compared to the Wildtype, and more bad steps compared to the Wildtype. Overall, the total good steps and bad steps across mice groups are differently distributed. 
>>>>>>> 6c6ce8d3e481402dda06d4269fe36f877b710ca9
<<<<<<< HEAD

=======
>>>>>>> 2147f11e9d38e314c422005cd6c8ceef4ae8aef8

# Software

Self-written software used for this project:

```{r}
script_names <- c("cleaning_extracting.Rmd", "anova_model.Rmd", "eda.Rmd", "dlc_model.ipynb")
descriptions <- c("A script to clean and transform data for appropriate analysis", "A script for creating visualizations and statistical analyses (ANOVA) on two datasets ('post_injury' and 'raw_post_injury') to understand the differences in specific variables across different 'type' groups in the two datasets", "An exploratory data analysis (EDA) script for visualizing ladder beam performance and tracking individual paws throughout a single video", "A data analysis notebook to train model using DeepLabCut to create labeled video")

as.data.frame(cbind(script_names, descriptions)) %>% 
  rename(Scripts = script_names,
         Descriptions = descriptions) %>% 
  kable(escape = T, 
        caption = "",
        align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

Third-party software and libraries used:

```{r}
script_names <- c("DeepLabCut (DLC)", "TensorFlow")
descriptions <- c("A software package for animal pose estimation using deep neural networks", "A Python library for machine learning, mainly on deep neural networks")

as.data.frame(cbind(script_names, descriptions)) %>% 
  rename(Scripts = script_names,
         Descriptions = descriptions) %>% 
  kable(escape = T, 
        caption = "",
        align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

# Experiments and Evaluation
Through the initial iterations of training the deep neural network, DeepLabCut reported 10 iterations with an error rate of 34.955% based on a p-value of 0.005 where it plateuoed at around 0.003% error rate after 10,000 iterations. After running it for 166,570 iterations, it ended at 0.00096% error rate with a p-value of 0.02. The runtime took around _______hours to train the neural network. 

After that, we were able to use DLC to create plots to analyze the accuracy of the trained neural network on the videos we created. From this it outputted CSV files and plots which showed the x versus y coordinates of the skeleton structure, body parts coordinates each frame, likelihood of each bodypart per frame, and the delta x and delta y count by body part. 

The x and y coordinate plots versus time plot should be continuous, but because of the obstructions, it is dotted points which shows the difficulty the neural network had in identifying the body parts as it moved across the ladder beams. 

The likelihood plot shows, 

The histogram of each body parts delta x and y shows the 

(SHOW PLOTS OF NEW STUFF) 

Through analysis of the videos and files the containing the results of the deep neural network on the videos, it showed the coordinates and likelihood of each part of the mouses skeleton across each frame of the video. They were able to accurately track the body parts a majority of the time but the obstructions from the ladder beams made it impossible to track all parts of the mouse 100% of the time. Additionally, although the videos were taken in higher quality and from a mounted camera, the distance from the mouse made it difficult to manually label let alone for the neural network to process. This is why there are many gaps in the data and rarely times where it detects the entire skeleton of the mouse at once. Looking frame by frame, you can see that it struggles to label all the parts with high confidence and often is unsure of whether the whiter parts of the body are the nose or a paw and where the middle, black parts of the body are due to these same regions. However, in the video, when it does detect the body part, it is accurate a majority of the time. 

Training iterations: 		166500	
%Training dataset: 		95				
Shuffle number: 		1
Train error(px): 		105.05
Test error(px): 			44.17
p-cutoff used: 			0.6
Train error with p-cutoff: 	16.56
Test error with p-cutoff:	17.35


# Notebook Description

# Members Participation

```{r echo = FALSE}
covariates <- c("task 1")

giles <- c("100%")
nathan <- c("100%")
alex <- c("100%")
vinh <- c("100%")
owen <- c("100%")

workload_summary <- data.frame(covariates,
                               linebreak(giles),
                               linebreak(nathan), 
                               linebreak(alex),
                               linebreak(vinh),
                               linebreak(owen))
                               
colnames(workload_summary) <- c("Task", "Giles", "Nathan", "Alex", "Vinh", "Owen")

kable(workload_summary, 
      escape = T, 
      caption = "Percentage of workload across group members",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```


# Discussion and Conclusion

*What did you learn about the methods and algorithms you worked with? What did you learn about their strengths? And their limitations?*

> In our project, we worked with DeepLabCut, a deep learning-based software for tracking body parts in videos. We found that DeepLabCut has significant strengths in accurately and efficiently tracking the movement of mice during the ladder beam task.However, collecting and annotating a large dataset can be time-consuming and labor-intensive. 

*What ended up being harder than you expected in your project? What was surprising about your project?*

> A surprising aspect of the project was the complexity of the mouse movements captured in the ladder beam task videos. The variability in step patterns, paw placements, and subtle differences in behavior among mice posed challenges in accurately tracking and analyzing the data.

*What other lessons did you learn, expected or unexpected (e.g., perhaps about the tools you used, if you used anything out of the ordinary?*

> test text

*If you were in charge of a research lab, what ideas and directions might you invest in over the next year or two to try to make major progress on this problem? Feel free to be speculative in discussing possible future directions.*

> In the future, we would film the mouse doing the ladder beam test in a more standarized way rather than hand filming. Ultimately, setting up a better working environment for pose estimation in the videos.
 
