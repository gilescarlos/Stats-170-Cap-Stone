---
title: "Assessing Stem Cell Therapeutics in Murine Models"
author: | 
  | Giles Carlos, 54951701, gpcarlos@uci.edu
  | Nathan Gin, 67117388, nbgin@uci.edu
  | Alexander Nathaneal, 54951701, anathana@uci.edu
  | Vinh Nguyen, 50036019, vinhhn2@uci.edu
  | Owen Sitiabudi, 54951701, ositiabu@uci.edu
date: "Github Repository: https://github.com/gilescarlos/Stats-170-Cap-Stone"
output:
  pdf_document: 
    number_sections: true
  html_document:
    number_sections: true
---

```{r echo = FALSE, include = FALSE}
library(tidyverse)
library(kableExtra)
library(knitr)
library(dplyr)
library(readr)
library(ggplot2)
library(ggpubr)
library(jpeg)
library(png)

post_injury <- read_csv(here::here("data/post_injury.csv"))


dlc_train <- read_csv(here::here("data/dlc_train_example_video.csv"))

frame <- readPNG(here::here("data/train/DLC Example Train Data-Giles-2023-04-26/labeled-data/MVI_8324/img1041.png"))
```


# Introduction and Problem Statement

Spinal cord injury (SCI) is a debilitating condition that impacts up to 300,000 individuals in the U.S. each year. As such, a significant focus of stem cell research is dedicated to developing therapeutics that could help bring affected individuals’ livelihood back. Likewise, the tests and methods used to assess different therapeutics are incredibly important. The efficiency and rigor of these tests allow for discovery of novel therapies and help advance the research field dedicated to solving spinal cord injury. The ladder beam test is a behavioral method for assessing recovery following SCI in murine models. During the test, mice must walk across a ladder with fifty rungs. Injured mice are expected to have more missteps while recovering mice should have more plantar or sufficient steps. However, to properly utilize this test our sponsors must spend several hours analyzing hundreds of videos of mice completing the task in order to individually score each mouse's performance. Consequently, this tedious process tends to slow down the lab's workflow and some automation would provide a significant increase in efficiency. Streamlining the ladder beam task and its data analysis would allow for significant efficiency in retrieving data necessary for the advancement of SCI research and therapeutics. Our primary goal is to use appropriate machine learning algorithms and build off existing research to aid in the lab’s data collection process for the ladder beam task. Secondly, we will assess the effectiveness of different treatments through appropriate statistical models and hypothesis tests. 

# Related Work

Several other labs have encountered this bottleneck in efficiency and have aimed to address this problem as well. One such solution is DeepLabCut^[Mathis, A., Mamidanna, P., Cury, K.M. et al. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci 21, 1281–1289 (2018). https://doi.org/10.1038/s41593-018-0209-y], which is an open source software developed in Python that utilizes a deep neural network to track various body parts in multiple species across a broad collection of behaviors or physical assessments. Another study was able to utilize the software to conduct a comprehensive 3D gait analysis of mice after focal cerebral ischemia^[Weber, R.Z., Mulders, G., Kaiser, J. et al. Deep learning-based behavioral profiling of rodent stroke recovery. BMC Biol 20, 232 (2022). https://doi.org/10.1186/s12915-022-01434-9]. The authors concluded that using a previously trained data set for tracking mice movement, their own recordings of mice completing the ladder beam task, and the DeepLabCut neural network provides accurate and sensitive data to describe the complex recovery of rodents following a stroke. Other researchers have also been successful in building upon DeepLabCut and creating their own toolbox utilizing a convolutional neural network appropriate for their recording equipment^[Aljovic, A., Zhao, S., Chahin, M. et al. A deep learning-based toolbox for Automated Limb Motion Analysis (ALMA) in murine models of neurological disorders. Commun Biol 5, 131 (2022). https://doi.org/10.1038/s42003-022-03077-6].

# Data Sets

We obtained our data from our sponsors at the UCI Stem Cell Research Center. Specifically, we received about a hundred videos of mice completing the ladder beam task and the corresponding manually labeled excel sheet corresponding to the videos. 

```{r echo = FALSE}
kable(head(post_injury, 10),
      escape = T, caption = "Example of First 10 Rows of Manually Input Data Set Obtained from Ladder Beam Task",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

```{r, results= FALSE, echo = FALSE}
n_row <- nrow(post_injury)
n_col <- ncol(post_injury)
summary(post_injury)
str(post_injury)
```

The post_injury data set has `r n_row` rows and `r n_col` columns where each column represents a single variable. The animal and type variables are categorical (nominal) and the rest of the variables are numerical (discrete). 

```{r echo = FALSE}
kable(head(dlc_train, 10),
    escape = T, caption = "Example of First 10 Rows of Training Data from a Single Video",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

The above table corresponds to a single training data set from one video of the ladder beam task being completed. From this particular video, nineteen frames were extracted which produced a data set with `r nrow(dlc_train)` rows and `r ncol(dlc_train)` columns. Each row represents a the location of one of the mouse's paws during a particular frame from a specific video. The video column indicates what video the frames were extracted from. Likewise, the frame column indicates which particular frame the body part was being tracked. Lastly, the body part, x, and y column correspond to which paw, the x coordinate, and the y coordinate, respectively. As we obtain more videos from our collaborators we plan on having a much larger training set with multiple videos and more frames. 

# Overall Technical Approach

## Data Wrangling

In order to utilize the videos provided by us, we needed an efficient tool for extracting frames in the video and labeling the location of mouse paws. We utilized DeepLabCut (DLC), an open source Python tool for developing models capable of tracking animal behavior and movement. The process for extracting our data from this tool goes as follows. First, we input a video or list of videos that we wish to obtain training data from into DLC. DLC then extracts a particular set of frames from each video according to the options we specify. Next, we individually label each frame by marking the location of each of the four mouse paws. Lastly, from those labeled frames DLC produces a training data set. 

However, the training data must then be pre-processed since the outputted format is not efficient to work with. As shown in the table below, each frame corresponds to a single row but the names for the columns need to be cleaned. In order to clean the training dataset initially produced by DLC into the table described in the Dataset section, the column names had to be changed and rows could be broken down to represent multiple body parts. First, we removed the scorer's name since it is irrelevant to the data. The columns containing the video file and the frame were given appropriate names. Then, each body part was given a correct column name. For example, bodypart1 corresponded to the front left paw of the mouse. Lastly, each individual row was transformed into four rows, one corresponding to each paw of the mouse at that specific frame. 

```{r message = FALSE, echo = FALSE}
unclean_train_data <- read_csv(here::here("data/train/DLC Example Train Data-Giles-2023-04-26/labeled-data/MVI_8324/CollectedData_Giles.csv"))

kable(head(unclean_train_data[,1:5], 10),
    escape = T, caption = "Example of First 10 Rows and 5 Columns of Uncleaned Training Data from a Single Video",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```



## Exploratory Data Analysis

```{r echo = FALSE}
post_injury %>% 
  mutate(type = case_when(type == "w" ~ "Wildtype", 
                          type == "k" ~ "Knock-out",
                          type == "v" ~ "Vehicle")) %>% 
  ggplot(aes(x = type, y = ave_bad)) + 
  geom_boxplot() + 
  labs(x = "Type of Mice", y = "Average # Errors", title = "Distribution of Ladder Beam Performance Across Mice Groups") + 
  theme_classic()
```

```{r echo = FALSE, warning = FALSE}
dlc_train %>% 
  filter(frame == "img1041.png") %>% 
  mutate(bodypart = case_when(bodypart == "back_left_paw" ~ "Back Left Paw",
                   bodypart == "back_right_paw" ~ "Back Right Paw",
                   bodypart == "front_left_paw" ~ "Front Left Paw",
                   bodypart == "front_right_paw" ~ "Front Right Paw")) %>% 
  ggplot(aes(x = x, y = y, color = bodypart)) + 
  background_image(frame) +
  geom_point() +
  ylim(1080, 0) + 
  xlim(0, 1920) + 
  labs(x = "X",
       y = "Y", 
       color = "Body Part")

dlc_train %>% 
  mutate(bodypart = case_when(bodypart == "back_left_paw" ~ "Back Left Paw",
                   bodypart == "back_right_paw" ~ "Back Right Paw",
                   bodypart == "front_left_paw" ~ "Front Left Paw",
                   bodypart == "front_right_paw" ~ "Front Right Paw")) %>% 
  ggplot(aes(x = x, y = y, color = bodypart)) + 
  geom_point() +
  ylim(1080, 0) + 
  xlim(0, 1920) +
  labs(x = "X",
       y = "Y", 
       color = "Body Part",
       title = "Tracking Individual Paws Throughout a Single Video")
```

The two plots above, describe how the paws are tracked in a video and the general behavior of each paw. The first plot, indicates that we are tracking each paw by emphasizing the location of the toes. The second plot describes the natural behavior one would expect for the paws of a mouse. That is, the front paws remain in front of the back paws for majority of the video. It must be noted that the recordings were not done with a stationary camera so although the mouse may have been moving forward, during the frames it may appear that the mouse is not moving that much. 

```{r echo=FALSE, message = FALSE}
post_injury %>% 
  mutate(type = case_when(type == "w" ~ "Wildtype", 
                          type == "k" ~ "Knock-out",
                          type == "v" ~ "Vehicle")) %>% 
ggplot(aes(x=total_good)) + 
  geom_histogram(col=I("white")) + 
  labs(title='Distribution of Total Good Steps Across Mice Groups', x='Total Good Steps', y='Mouse Count') +
  facet_wrap(vars(type))
```

```{r echo=FALSE, message = FALSE}
ggplot(data=post_injury, aes(x=total_bad)) + 
  geom_histogram(col=I('white')) + 
  labs(title='Distribution of Total Bad Steps Across Mice Groups', x='Mouse Count', y='Total Bad Steps') +
  facet_wrap(vars(type))
```

The above two graphs show the distribution of the total good and bad steps across the mice groups. 


# Software

# Experiments and Evaluation

# Notebook Description

# Members Participation

```{r echo = FALSE}
covariates <- c("task 1")

giles <- c("100%")
nathan <- c("100%")
alex <- c("100%")
vinh <- c("100%")
owen <- c("100%")

workload_summary <- data.frame(covariates,
                               linebreak(giles),
                               linebreak(nathan), 
                               linebreak(alex),
                               linebreak(vinh),
                               linebreak(owen))
                               
colnames(workload_summary) <- c("Task", "Giles", "Nathan", "Alex", "Vinh", "Owen")

kable(workload_summary, 
      escape = T, 
      caption = "Percentage of workload across group members",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```


# Discussion and Conclusion

*What did you learn about the methods and algorithms you worked with? What did you learn about their strengths? And their limitations?*

> test text

*What ended up being harder than you expected in your project? What was surprising about your project?*

> test

*What other lessons did you learn, expected or unexpected (e.g., perhaps about the tools you used, if you used anything out of the ordinary?*

> test text

*If you were in charge of a research lab, what ideas and directions might you invest in over the next year or two to try to make major progress on this problem? Feel free to be speculative in discussing possible future directions.*

> test text
 
