---
title: "Assessing Stem Cell Therapeutics in Murine Models"
author: | 
  | Giles Carlos, 54951701, gpcarlos@uci.edu
  | Nathan Gin, 54951701, nbgin@uci.edu
  | Alexander Nathaneal, 54951701, anathana@uci.edu
  | Vinh Nguyen, 54951701, vinhhn2@uci.edu
  | Owen Sitiabudi, 54951701, ositiabu@uci.edu
date: "Github Repository: https://github.com/gilescarlos/Stats-170-Cap-Stone"
output:
  pdf_document: 
    number_sections: true
  html_document:
    number_sections: true
---

```{r echo = FALSE, include = FALSE}
library(tidyverse)
library(kableExtra)
library(knitr)
library(dplyr)
library(readr)
library(ggplot2)

post_injury <- read_csv(here::here("post_injury.csv"))
```


# Introduction and Problem Statement

Spinal cord injury (SCI) is a debilitating condition that impacts up to 300,000 individuals in the U.S. each year. As such, a significant focus of stem cell research is dedicated to developing therapeutics that could help bring affected individuals’ livelihood back. Likewise, the tests and methods used to assess different therapeutics are incredibly important. The efficiency and rigor of these tests allow for discovery of novel therapies and help advance the research field dedicated to solving spinal cord injury. The ladder beam test is a behavioral method for assessing recovery following SCI in murine models. During the test, mice must walk across a ladder with fifty rungs. Injured mice are expected to have more missteps while recovering mice should have more plantar or sufficient steps. However, to properly utilize this test our sponsors must spend several hours analyzing hundreds of videos of mice completing the task in order to individually score each mouse's performance. Consequently, this tedious process tends to slow down the lab's workflow and some automation would provide a significant increase in efficiency. Streamlining the ladder beam task and its data analysis would allow for significant efficiency in retrieving data necessary for the advancement of SCI research and therapeutics. Our primary goal is to use appropriate machine learning algorithms and build off existing research to aid in the lab’s data collection process for the ladder beam task. Secondly, we will assess the effectiveness of different treatments through appropriate statistical models and hypothesis tests. 

# Related Work

Several other labs have encountered this bottleneck in efficiency and have aimed to address this problem as well. One such solution is DeepLabCut^[Mathis, A., Mamidanna, P., Cury, K.M. et al. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci 21, 1281–1289 (2018). https://doi.org/10.1038/s41593-018-0209-y], which is an open source software developed in Python that utilizes a deep neural network to track various body parts in multiple species across a broad collection of behaviors or physical assessments. Another study was able to utilize the software to conduct a comprehensive 3D gait analysis of mice after focal cerebral ischemia^[Weber, R.Z., Mulders, G., Kaiser, J. et al. Deep learning-based behavioral profiling of rodent stroke recovery. BMC Biol 20, 232 (2022). https://doi.org/10.1186/s12915-022-01434-9]. The authors concluded that using a previously trained data set for tracking mice movement, their own recordings of mice completing the ladder beam task, and the DeepLabCut neural network provides accurate and sensitive data to describe the complex recovery of rodents following a stroke. Other researchers have also been successful in building upon DeepLabCut and creating their own toolbox utilizing a convolutional neural network appropriate for their recording equipment^[Aljovic, A., Zhao, S., Chahin, M. et al. A deep learning-based toolbox for Automated Limb Motion Analysis (ALMA) in murine models of neurological disorders. Commun Biol 5, 131 (2022). https://doi.org/10.1038/s42003-022-03077-6].

# Data Sets

We obtained our data from our sponsors at the UCI Stem Cell Research Center. Specifically, we received about a hundred videos of mice completing the ladder beam task and the corresponding manually labeled excel sheet corresponding to the videos. 

```{r echo = FALSE}
kable(head(post_injury, 10),
      escape = T, caption = "Example of First 10 Rows of Manually Input Data Set Obtained from Ladder Beam Task",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

```{r echo = FALSE}
nrow(post_injury)
ncol(post_injury)
summary(post_injury)
str(post_injury)
```

The post_injury data set has 30 rows and 7 columns where each column consists of 1 variable. The animal and type variables' type are categorical (nominal) and the rest of the variables are numerical variable (discrete). 

```{r echo=FALSE}
post_injury %>% 
  mutate(type = case_when(type == "w" ~ "Wildtype", 
                          type == "k" ~ "Knock-out",
                          type == "v" ~ "Vehicle")) %>% 
ggplot(aes(x=total_good)) + 
  geom_histogram(col=I("white")) + 
  labs(title='Distribution of Total Good Steps Across Mice Groups', x='Total Good Steps', y='Mouse Count') +
  facet_wrap(vars(type))
```
```{r echo=FALSE}
ggplot(data=post_injury, aes(x=total_bad)) + 
  geom_histogram(col=I('white')) + 
  labs(title='Distribution of Total Bad Steps Across Mice Groups', x='Mouse Count', y='Total Bad Steps') +
  facet_wrap(vars(type))
```

The above two graphs show the distribution of the total good and bad steps across the mice groups. 


# Overall Technical Approach

## Data Wrangling

## Exploratory Data Analysis

```{r echo = FALSE}
post_injury %>% 
  mutate(type = case_when(type == "w" ~ "Wildtype", 
                          type == "k" ~ "Knock-out",
                          type == "v" ~ "Vehicle")) %>% 
  ggplot(aes(x = type, y = ave_bad)) + 
  geom_boxplot() + 
  labs(x = "Type of Mice", y = "Average # Errors", title = "Distribution of Ladder Beam Performance Across Mice Groups") + 
  theme_classic()
```


# Software

# Experiments and Evaluation

# Notebook Description

# Members Participation

```{r echo = FALSE}
covariates <- c("task 1")

giles <- c("100%")
nathan <- c("100%")
alex <- c("100%")
vinh <- c("100%")
owen <- c("100%")

workload_summary <- data.frame(covariates,
                               linebreak(giles),
                               linebreak(nathan), 
                               linebreak(alex),
                               linebreak(vinh),
                               linebreak(owen))
                               
colnames(workload_summary) <- c("Task", "Giles", "Nathan", "Alex", "Vinh", "Owen")

kable(workload_summary, 
      escape = T, 
      caption = "Percentage of workload across group members",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```


# Discussion and Conclusion

*What did you learn about the methods and algorithms you worked with? What did you learn about their strengths? And their limitations?*

> test text

*What ended up being harder than you expected in your project? What was surprising about your project?*

> test

*What other lessons did you learn, expected or unexpected (e.g., perhaps about the tools you used, if you used anything out of the ordinary?*

> test text

*If you were in charge of a research lab, what ideas and directions might you invest in over the next year or two to try to make major progress on this problem? Feel free to be speculative in discussing possible future directions.*

> test text
 
