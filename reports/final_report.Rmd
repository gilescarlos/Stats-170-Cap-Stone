---
title: "Assessing Stem Cell Therapeutics in Murine Models"
author: | 
  | Giles Carlos, 54951701, gpcarlos@uci.edu
  | Nathan Gin, 67117388, nbgin@uci.edu
  | Alexander Nathaneal, 46645315, anathana@uci.edu
  | Vinh Nguyen, 50036019, vinhhn2@uci.edu
  | Owen Sitiabudi, 19975215, ositiabu@uci.edu
date: "Github Repository: https://github.com/gilescarlos/Stats-170-Cap-Stone"
output:
  pdf_document: 
    number_sections: true
  html_document:
    number_sections: true
---

```{r echo = FALSE, include = FALSE}
library(tidyverse)
library(kableExtra)
library(knitr)
library(dplyr)
library(readr)
library(ggplot2)
library(ggpubr)
library(jpeg)
library(png)
library(gridExtra)

post_injury <- read_csv(here::here("data/post_injury.csv"))

dlc_train <- read_csv(here::here("data/dlc_train_example_video.csv"))

frame <- readPNG(here::here("data/train/UCI_HD_Label-NG-2023-05-19/labeled-data/20230112_145948/img0924.png"))
```


# Introduction and Problem Statement

Spinal cord injury (SCI) is a debilitating condition that impacts up to 300,000 individuals in the U.S. each year. As such, a significant focus of stem cell research is dedicated to developing therapeutics that could help bring affected individuals’ livelihood back. Likewise, the tests and methods used to assess different therapeutics are incredibly important. The efficiency and rigor of these tests allow for discovery of novel therapies and help advance the research field dedicated to solving spinal cord injury. The ladder beam test is a behavioral method for assessing recovery following SCI in murine models. There are 3 types of mice: Knock-out, Wildtype, and Vehicle. The Knock-out mice have their CD44 gene removed to study its absent effect in recovery. The Wildtype are the control group while the Vehicle type have an additional injection. During the test, mice must walk across a ladder with fifty rungs. Injured mice are expected to have more missteps while recovering mice should have more plantar or sufficient steps. However, to properly utilize this test our sponsors must spend several hours analyzing hundreds of videos of mice completing the task in order to individually score each mouse's performance. Consequently, this tedious process tends to slow down the lab's workflow and some automation would provide a significant increase in efficiency. Streamlining the ladder beam task and its data analysis would allow for significant efficiency in retrieving data necessary for the advancement of SCI research and therapeutics. Our primary goal is to use appropriate machine learning algorithms and build off existing research to aid in the lab’s data collection process for the ladder beam task. Secondly, we will assess the effectiveness of different treatments through appropriate statistical models and hypothesis tests. 

# Related Work

Several other labs have encountered this bottleneck in efficiency and have aimed to address this problem as well. One such solution is DeepLabCut^[Mathis, A., Mamidanna, P., Cury, K.M. et al. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci 21, 1281–1289 (2018). https://doi.org/10.1038/s41593-018-0209-y], which is an open source software developed in Python that utilizes a deep neural network to track various body parts in multiple species across a broad collection of behaviors or physical assessments. Another study was able to utilize the software to conduct a comprehensive 3D gait analysis of mice after focal cerebral ischemia^[Weber, R.Z., Mulders, G., Kaiser, J. et al. Deep learning-based behavioral profiling of rodent stroke recovery. BMC Biol 20, 232 (2022). https://doi.org/10.1186/s12915-022-01434-9]. The authors concluded that using a previously trained data set for tracking mice movement, their own recordings of mice completing the ladder beam task, and the DeepLabCut neural network provides accurate and sensitive data to describe the complex recovery of rodents following a stroke. Other researchers have also been successful in building upon DeepLabCut and creating their own toolbox utilizing a convolutional neural network appropriate for their recording equipment^[Aljovic, A., Zhao, S., Chahin, M. et al. A deep learning-based toolbox for Automated Limb Motion Analysis (ALMA) in murine models of neurological disorders. Commun Biol 5, 131 (2022). https://doi.org/10.1038/s42003-022-03077-6]. However, these other labs had access to several camera angles and performed analysis on other behavioral tasks besides the ladder beam task. For example, in one study a lab obtained training data from three camera angles that could be utilized by DeepLabCut, two side-views and one bottom-up view. In our case, we only have a bottom-up camera view where the obstruction of the ladder rungs can be a source of inaccuracy.

# Data Sets

We obtained our data from our sponsors at the UCI Stem Cell Research Center. Specifically, we received about a hundred videos of mice completing the ladder beam task and the corresponding manually labeled excel sheet corresponding to the videos. 

```{r echo = FALSE}
options(digits = 3)

kable(head(post_injury, 10),
      escape = T, 
      col.names = c("Animal ID", "Total Good Steps", "Total Bad Steps", "Avg Good Steps", "Avg Bad Steps", "LB Score", "Type"),
      caption = "Example of First 10 Rows of Manually Input Data Set Obtained from Ladder Beam Task",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE) %>% 
  column_spec(2:5, width = "4em")

```

```{r, results= FALSE, echo = FALSE}
n_row <- nrow(post_injury)
n_col <- ncol(post_injury)
summary(post_injury)
str(post_injury)
```

The post_injury data set has `r n_row` rows and `r n_col` columns where each column represents a single variable. The animal and type variables are categorical (nominal) and the rest of the variables are numerical (discrete). Total_good and Total_bad measures the quality of the steps of the mouse as it traverse through the ladder beam. Type variable indicate 1 of the 3 mouse types: wild (w), knock-out (k), and vehicle (v). Lb_score shows the overall performance of each mouse On average, each mouse has 42.83 good steps and 7.15 bad steps. The mean lb score of the mice is 85.69, with a lowest of 72.33 and a highest of 97.00. The highest total good steps the mouse has is 291 and the lowest is 217 good steps. While for the bad steps, the highest is 83 and the lowest is 9 bad steps.

```{r echo = FALSE}
kable(head(dlc_train, 10),
      col.names = c("Video", "Frame", "Bodypart", "X", "Y"),
      escape = T, caption = "Example of First 10 Rows of Training Data from a Single Video",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

The above table corresponds to a single training data set from one video of the ladder beam task being completed. From this particular video, nineteen frames were extracted which produced a data set with `r nrow(dlc_train)` rows and `r ncol(dlc_train)` columns. Each row represents a the location of one of the mouse's paws during a particular frame from a specific video. The video column indicates what video the frames were extracted from. Likewise, the frame column indicates which particular frame the body part was being tracked. Lastly, the body part, x, and y column correspond to which paw or part of the body, the x coordinate, and the y coordinate, respectively. In total, we obtained training data sets from three separate videos. It should be noted that in each data set there are several missing values in the x and y columns indicating that a particular part of the body was blocked or obstructed by a ladder rung. Therefore, that specific body part was not able to be labeled. 

# Overall Technical Approach

## Data Wrangling

In order to utilize the videos provided by us, we needed an efficient tool for extracting frames in the video and labeling the location of mouse paws. We utilized DeepLabCut (DLC), an open source Python tool for developing models capable of tracking animal behavior and movement. The process for extracting our data from this tool goes as follows. First, we input a video or list of videos that we wish to obtain training data from into DLC. DLC then extracts a particular set of frames from each video according to the options we specify. Next, we individually label each frame by marking the location of each of the four mouse paws. Lastly, from those labeled frames DLC produces a training data set. 

```{r message = FALSE, echo = FALSE}
unclean_train_data <- read_csv(here::here("data/train/UCI_HD_Label-NG-2023-05-19/labeled-data/20230112_145948/CollectedData_NG.csv"))

kable(head(unclean_train_data[,1:5], 10),
    escape = T, caption = "Example of First 10 Rows and 5 Columns of Uncleaned Training Data from a Single Video",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

However, the training data must then be pre-processed since the outputted format is not efficient to work with. As shown in the table above, each frame corresponds to a single row but the names for the columns need to be cleaned. In order to clean the training dataset initially produced by DLC into the table described in the Dataset section, the column names had to be changed and rows could be broken down to represent multiple body parts. First, we removed the scorer's name since it is irrelevant to the data. The columns containing the video file and the frame were given appropriate names. Then, each body part was given a correct column name. For example, FrontLeft corresponded to the front left paw of the mouse. Lastly, each individual row was transformed into four rows, one corresponding to each paw of the mouse at that specific frame. 


## Exploratory Data Analysis

```{r echo = FALSE}
post_injury %>% 
  group_by(type) %>% 
  summarise(mean_steps = mean(ave_bad),
            var_steps = var(ave_bad)) %>%
  mutate(type = case_when(type == "k" ~ "Knockout",
                          type == "v" ~ "Vehicle",
                          type == "w" ~ "Wildtype")) %>% 
  rename(Type = type, 
        `Mean Bad Steps` = mean_steps,
        `Variance Bad Steps` = var_steps) %>% 
  kable(escape = T, 
        caption = "Summary statistics of bad steps for each type of mouse") %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)

post_injury %>% 
  mutate(type = case_when(type == "w" ~ "Wildtype", 
                          type == "k" ~ "Knock-out",
                          type == "v" ~ "Vehicle")) %>% 
  ggplot(aes(x = type, y = ave_bad)) + 
  geom_boxplot() + 
  labs(x = "Type of Mice", y = "Average # Errors", title = "Distribution of Ladder Beam Performance Across Mice Groups") + 
  theme_classic()
```

When comparing the three groups of mice, we can see that on average the knock-out mice performed the worst while the wild type performed the best. The vehicle group and wildtype group appear to have similar variance while the knock-out group's variance is slightly higher. Based on the plot and table above, there may be some evidence that the stem cell therapeutic helps certain groups of mice in their recovery a little more. 

```{r echo = FALSE, warning = FALSE}
track_paws1<- dlc_train %>% 
  filter(frame == "img0924.png") %>% 
  mutate(bodypart = case_when(bodypart == "back_left_paw" ~ "Back Left Paw",
                   bodypart == "back_right_paw" ~ "Back Right Paw",
                   bodypart == "front_left_paw" ~ "Front Left Paw",
                   bodypart == "front_right_paw" ~ "Front Right Paw",
                   bodypart == "nose" ~ "Nose",
                   bodypart == "tail" ~ "Tail", 
                   bodypart == "front_mid" ~ "Front Middle",
                   bodypart == "back_mid" ~ "Back Middle")) %>% 
  ggplot(aes(x = x, y = y, color = bodypart)) + 
  background_image(frame) +
  geom_point(size = 1.5) +
  ylim(3840, 0) + 
  xlim(0, 2160) +  
  labs(x = "X",
       y = "Y", 
       color = "Body Part") + 
  theme(legend.position = "none")

track_paws2 <- dlc_train %>% 
  filter(bodypart %in% c("back_left_paw", "back_right_paw", "front_left_paw", "front_right_paw")) %>% 
  mutate(bodypart = case_when(bodypart == "back_left_paw" ~ "Back Left Paw",
                   bodypart == "back_right_paw" ~ "Back Right Paw",
                   bodypart == "front_left_paw" ~ "Front Left Paw",
                   bodypart == "front_right_paw" ~ "Front Right Paw")) %>% 

  ggplot(aes(x = x, y = y, color = bodypart)) + 
  geom_point() +
  ylim(3840, 0) + 
  xlim(0, 2160) + 
  labs(x = "X",
       y = "Y", 
       color = "Body Part") + 
  theme(legend.position = c(0.25, 0.875),
        legend.key.size = unit(0.25, 'cm'))

grid.arrange(track_paws1, track_paws2, ncol = 2)
```

The two plots above, describe how the paws are tracked in a video and the general behavior of each paw. The first plot, indicates that we are tracking each paw by emphasizing the location of the toes. Although there are only four paws, four additional points were labeled on the mouse to better track the skeletal structure. Specifically, the nose, tail, middle point between the front paws, and middle point between the back paws were labeled. The second plot describes the natural behavior one would expect for the paws of a mouse. That is, the front paws remain in front of the back paws for majority of the video. It must be noted that the recordings were done with a stationary camera so the mouse was moving forward for the most part, but there may be instances in the video where the mouse backtracks.

```{r echo=FALSE, message = FALSE}
post_injury %>%
  mutate(type = case_when(
    type == "w" ~ "Wildtype",
    type == "k" ~ "Knock-out",
    type == "v" ~ "Vehicle"
  )) %>%
  ggplot(aes(x = total_good)) +
  geom_density(fill = "white", alpha = 0.5) +
  labs(
    title = "Distribution of Total Good Steps Across Mice Groups",
    x = "Total Good Steps",
    y = "Density"
  ) +
  facet_wrap(vars(type))
```

```{r echo=FALSE, message = FALSE}
post_injury %>%
  mutate(type = case_when(
    type == "w" ~ "Wildtype",
    type == "k" ~ "Knock-out",
    type == "v" ~ "Vehicle"
  )) %>%
  ggplot(aes(x = total_bad)) +
  geom_density(fill = "white", alpha = 0.5) +
  labs(
    title = "Distribution of Total Bad Steps Across Mice Groups",
    x = "Total Bad Steps",
    y = "Density"
  ) +
  facet_wrap(vars(type))
```

The above two graphs show the distribution of the total good and bad steps across the mice groups. According to the graphs, almost every mouse having different density of total good and bad steps. The Vehicle type has less good steps compared to the Wildtype, and more bad steps compared to the Wildtype. Overall, the total good steps and bad steps across mice groups are differently distributed. 

## Data Modeling

Our main interest is to build a model that can accurately track a mouse paw as they complete the ladder beam task and capable of classifying mouse steps as good ones or bad ones. As a result, we utilize DeepLabCut for the object detection model, which is a software package for animal pose estimation that allows the training of a deep neural network using trained data. 

We start by uploading the videos and then extracting the frames to be manually labeled as the training data. We design the skeleton of the mouse and manually label the mouse's body parts and rungs throughout these frames for the neural network to be trained on. Through this process we then can create the training data sets. After obtaining the training data sets, we train the network, while saving for every 100 iterations with a total of 166500 iterations. We then evaluate the trained network by computing the mean average Euclidean error between the manual labels and the ones predicted by the network. Then we can use the trained network to analyze new videos and plot the mouse steps in x and y coordinate. 

```{r echo = FALSE}
aov_mod <- aov(total_bad ~ type, data = post_injury)
aov_sum <- summary(aov_mod)[[1]]
rownames(aov_sum) <- c("Type", "Residual")
colnames(aov_sum) <- c("DF", "Sum Squared Error", "Mean Squared Error", "F-Value", "Pr(> F)")

kable(aov_sum,
      escape = T, 
      caption = "ANOVA Model Summary",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```


We also built an ANOVA model comparing the total bad steps between the three types of mice. The Knock-out type has an average bad steps of 7.6, the Vehicle type has an average bad steps of 7.8, and the Wild type has an average bad steps of 6.1. The table above shows that at a significance level of 0.05 and with a p-value of 0.543, we can conclude that the average number of errors is not significantly different among the three types of mice after treatment. 

# Software

Self-written software used for this project, in order of use:

```{r echo = FALSE}
script_names <- c("cleaning_extracting.Rmd", 
                  "eda.Rmd", 
                  "anova_model.Rmd", 
                  "dlc_model.ipynb")
descriptions <- c("A script to clean and transform data for appropriate analysis", 
                  "An exploratory data analysis (EDA) script for visualizing ladder beam performance and tracking individual paws throughout a single video",
                  "A script for creating visualizations and statistical analyses (ANOVA) on two datasets ('post_injury' and 'raw_post_injury') to understand the differences in specific variables across different 'type' groups in the two datasets",  
                  "A data analysis notebook to train model using DeepLabCut to create labeled video")

as.data.frame(cbind(script_names, descriptions)) %>% 
  rename(Scripts = script_names,
         Descriptions = descriptions) %>% 
  kable(escape = T, 
        caption = "",
        align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE) %>% 
  column_spec(2, width = "30em")
```

Third-party software and libraries used:

```{r echo = FALSE}
script_names <- c("DeepLabCut (DLC)", "TensorFlow")
descriptions <- c("A software package for animal pose estimation using deep neural networks", "A Python library for machine learning, mainly on deep neural networks")

as.data.frame(cbind(script_names, descriptions)) %>% 
  rename(Scripts = script_names,
         Descriptions = descriptions) %>% 
  kable(escape = T, 
        caption = "",
        align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE)
```

# Experiments and Evaluation

## ANOVA Diagnostics

To check the validity for our ANOVA model we performed diagnostics to see if any of the following assumptions were violated: normality, constant variance, and independence. We know from the lab that each mouse was randomly assigned and tested independently so the independence assumption is not violated. Likewise, from our exploratory data analysis we saw that the variance across the three groups was fairly similar so constant variance can be assumed. 

```{r echo = FALSE}
qqnorm(aov_mod$residuals)
qqline(aov_mod$residuals)
```

However, as show in the plot above, heavy tails in the QQ plot indicate there is a possible violation to the normality assumption. This may be due to the small sample size.

## Neural Network

Through the initial iterations of training the deep neural network, DeepLabCut reported 10 iterations with an error rate of 34.955% based on a p-value of 0.005 where it plateaued at around 0.3% error rate after 10,000 iterations. After running it for 166,570 iterations, it ended at 0.096% error rate with a p-value of 0.02. The run time took around 16 hours to train the neural network. The training error came out to be 105.05 pixels and the testing error came out to be 44.17 pixels. However, with a p-value of 0.6 both training and testing had an error rate of around 17 pixels. The video dimensions were 3840 by 2160 pixels.

```{r echo = FALSE, message = FALSE, fig.height = 5.75}
library(png)
library(grid)
library(gridExtra)
library(magick)

histogram <- readPNG(here::here("data/images/145948_plots/hist.png"))
likelihood <- readPNG(here::here("data/images/145948_plots/plot-likelihood.png"))
xyplot <- readPNG(here::here("data/images/145948_plots/trajectory.png"))
xytime <- readPNG(here::here("data/images/145948_plots/plot.png"))

grid.arrange(rasterGrob(xyplot),
             rasterGrob(xytime),
             rasterGrob(likelihood),
             rasterGrob(histogram),
             ncol = 2)
grid.text("A)", x = unit(0.05, "npc"), y = unit(0.97, "npc"), draw = TRUE)
grid.text("B)", x = unit(0.55, "npc"), y = unit(0.97, "npc"), draw = TRUE)
grid.text("C)", x = unit(0.05, "npc"), y = unit(0.47, "npc"), draw = TRUE)
grid.text("D)", x = unit(0.55, "npc"), y = unit(0.47, "npc"), draw = TRUE)
```

We were then able to use DeepLabCut to create plots to analyze the accuracy of the trained neural network on the videos we created. From this it outputted CSV files and plots which showed the x versus y coordinates of the skeletal structure (A), skeletal structure coordinates each frame (B), likelihood of each body part in the skeletal structure each frame (C), and a histogram for the counts of delta x and delta y by body part (D). 

The x and y coordinate plots versus time plot should be continuous, but because of the obstructions, it became dotted points which shows the difficulty the neural network had in identifying the body parts as it moved across the ladder beams. 

The likelihood plot shows, the likelihood that the body part at each frame is predicted correctly. Ideally, the likelihood versus frames plot would keep a likelihood of one at the top of the graph if there was high confidence that the mouses body part would be there. However, in this situation, the likelihood of all the parts stays around the middle of the y axis. Another thing to notes is that the nose and front paws have the highest likelihood versus the tail and back of the mouse which have the lowest likelihood values. 

The histogram of each body parts delta x and y shows the difference in pixel distance between labels in consecutive frames. This count should all have a low delta x and delta y because it would show a consistent tracking of each body part. Large jumps in these values over a frame would mean that it is losing track of that body parts position. This corroborates the likelihood plot and shows the front of the mouse is better tracked than the tail and middle of the mouse. 

The videos were able to accurately track the body parts a majority of the time but the obstructions from the ladder beams made it impossible to track all parts of the mouse the entire time. Additionally, although the videos were taken in higher quality and from a mounted camera, the distance from the mouse made it difficult to manually label let alone for the neural network to process. This is why there are gaps in the data and rarely times where it detects the entire skeleton of the mouse at once. Looking frame by frame, you can see that it struggles to label all the parts with high confidence and often is unsure of whether the whiter parts of the body are the nose or a paw and where the middle, black parts of the body are due to these same reasons. However, the video shows accuracy when it does detect the body part in frame. 

# Notebook Description

# Members Participation

```{r echo = FALSE}
covariates <- c("Data Wrangling and Cleaning",
                "Exploratory Data Analysis",
                "ANOVA Modeling",
                "DLC Neural Net Modeling",
                "Report and Presentation Writing")

giles <- c("50%", "25%", "20%", "50%", "25%")
nathan <- c("50%", "25%", "20%", "50%", "25%")
alex <- c("0%", "25%", "30%", "0%", "20%")
vinh <- c("0%", "0%", "0%", "0%", "10%")
owen <- c("0%", "25%", "30%", "0%", "20%")

workload_summary <- data.frame(covariates,
                               linebreak(giles),
                               linebreak(nathan), 
                               linebreak(alex),
                               linebreak(vinh),
                               linebreak(owen))
                               
colnames(workload_summary) <- c("Task", "Giles", "Nathan", "Alex", "Vinh", "Owen")

kable(workload_summary, 
      escape = T, 
      caption = "Percentage of workload across group members",
      align = 'l') %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  row_spec(0, bold = TRUE) 
# %>% column_spec(2, width = "30em")
```


# Discussion and Conclusion

*What did you learn about the methods and algorithms you worked with? What did you learn about their strengths? And their limitations?*

> In our project, we worked with DeepLabCut, a deep learning-based software for tracking body parts in videos. We found that DeepLabCut has significant strengths in accurately and efficiently tracking the movement of mice during the ladder beam task.However, collecting and annotating a large dataset can be time-consuming and labor-intensive. 

*What ended up being harder than you expected in your project? What was surprising about your project?*

> A surprising aspect of the project was the complexity of the mouse movements captured in the ladder beam task videos. The variability in step patterns, paw placements, and subtle differences in behavior among mice posed challenges in accurately tracking and analyzing the data.

*What other lessons did you learn, expected or unexpected (e.g., perhaps about the tools you used, if you used anything out of the ordinary?*

> test text

*If you were in charge of a research lab, what ideas and directions might you invest in over the next year or two to try to make major progress on this problem? Feel free to be speculative in discussing possible future directions.*

> In the future, we would film the mouse doing the ladder beam test in a more standarized way rather than hand filming. Ultimately, setting up a better working environment for pose estimation in the videos.
 
